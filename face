import cv2
import pathlib
from deepface import DeepFace


def cam():

    cascade_path=pathlib.Path(cv2.__file__).parent.absolute() / "data/haarcascade_frontalface_default.xml"
    clf=cv2.CascadeClassifier(str(cascade_path))
    cam=cv2.VideoCapture(0)

    while True:
        ret,frame=cam.read()
        results=DeepFace.analyze(frame,actions=("gender","age","emotion"),enforce_detection=False)
        gender=results[0]["dominant_gender"]
        age=results[0]["age"]
        emotion = results[0]["dominant_emotion"]
        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        faces=clf.detectMultiScale(
            gray,scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30,30),
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        for(x,y,width,height) in faces:
            cv2.rectangle(frame,(x,y),(x+width,y+height),(255,255,0),2)
            cv2.putText(frame, f"age:{age}", (x,y+height+20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 3)
            cv2.putText(frame, f"gender:{gender}", (x,y+height+40), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 3)
            cv2.putText(frame, f"emotion:{emotion}", (x,y+height+60), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 3)
        

        cv2.imshow("Faces",frame)
        if(cv2.waitKey(1)==ord("q")):
            break
    cam.release()
    cv2.destroyAllWindows()

img=cv2.imread("a.jpg")
results=DeepFace.analyze(img,actions=("gender"))
print(gender:=results[0]["gender"])
